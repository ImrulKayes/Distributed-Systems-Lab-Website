<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1" />
<meta name="description" content="Distributed Systems Group at the University of South Florida" />
<meta name="keywords" content="distributed systems networking social research cutting-edge" />
	<title>Abstracts - Distributed Systems Group at USF</title>
<link href="../style.css" rel="stylesheet" type="text/css" />
</head>

<body>
<div id="container">
<div id="header"><h1>Abstracts</h1></div>
<div id="sub_header"></div>
<div id="main_content_top"></div>


<div id="main_content"> <div class="content"> 



<p class="paragraph_style"><a name="privacy_asonam"></a> Privacy Concerns vs. User Behavior in Community Question Answering
<p class="paragraph_style_1">

Community-based question answering (CQA) platforms are crowd-sourced services for sharing user expertise on various topics, from mechanical repairs to parenting. While they naturally build-in an online social network infrastructure, they carry a very different purpose from Facebook-like social networks, where users 'hang-out' with their friends and tend to share more personal information. It is unclear, thus, how the privacy concerns and their correlation with user behavior in an online social network translate into a CQA platform. This study analyzes one year of recorded traces from a mature CQA platform to understand the association between users' privacy concerns as manifested by their account settings and their activity in the platform. The results show that privacy preference is correlated with behavior in the community in terms of engagement, retention, accomplishments and deviance from the norm. We find privacy-concerned users have higher qualitative and quantitative contributions, show higher retention, report more abuses, have higher perception on answer quality and have larger social circles. However, at the same time, these users also exhibit more deviant behavior than the users with public profiles.

<p class="paragraph_style"><a name="cultures_ht"></a> Cultures in Community Question Answering
<p class="paragraph_style_1">

CQA services are collaborative platforms where users ask and answer questions. We investigate the influence of national culture on people's online questioning and answering behavior. For this, we analyzed a sample of 200 thousand users in Yahoo Answers from 67 countries. We measure empirically a set of cultural metrics defined in Geert Hofstede's cultural dimensions and Robert Levine's Pace of Life and show that behavioral cultural differences exist in community question answering platforms. We find that national cultures differ in Yahoo Answers along a number of dimensions such as temporal predictability of activities, contributionrelated behavioral patterns, privacy concerns, and power inequality


<p class="paragraph_style"><a name="indirect_ties"></a> The Power of Indirect Ties
<p class="paragraph_style_1">

While direct social ties have been intensely studied in the context of computer-mediated social networks, indirect ties (e.g., friends of friends) have seen little attention. Yet in real life, we often rely on friends of our friends for recommendations (of good doctors, good schools, or good babysitters), for introduction to a new job opportunity, and for many other occasional needs. In this work we attempt to 1) quantify the strength of indirect social ties, 2) validate the quantification, and 3) empirically demonstrate its usefulness for applications on two examples. We quantify social strength of indirect ties using a measure of the strength of the direct ties that connect two people and the intuition provided by the sociology literature. We evaluate the proposed metric by framing it as a link prediction problem and experimentally demonstrate that our metric accurately (up to 87.2%) predicts link's formation. We show via data-driven experiments that the proposed metric for social strength can be used successfully for social applications. Specifically, we show that it can be used for predicting the effects of information diffusion with an accuracy of up to 0.753. We also show that it alleviates known problems in friend-to-friend storage systems by addressing two previously documented shortcomings: reduced set of storage candidates and data availability correlations.

<p class="paragraph_style"><a name="test_cases"></a> The Network of Faults: A Complex Network Approach to Prioritize Test Cases for Regression Testing
<p class="paragraph_style_1">

Regression testing is performed to provide confidence that changes in a part of software do not affect other parts of the software. An execution of all existing test cases is the best way to re-establish this confidence. However, regression testing is an expensive process-there might be insufficient resources (e.g., time, workforce) to allow for the re-execution of all test cases. Regression test prioritization techniques attempt to re-order a regression test suite based on some criteria so that highest priority test cases are executed earlier. In this study, we prioritize test cases for regression testing based on the dependency network of faults. In software testing, it is common that some faults are the consequences of other faults (leading faults). Dependent faults can be removed if and only if the leading faults have been removed. Our goal is to prioritize test cases so that test cases that have exposed the leading faults in the system testing phase, are executed first in regression testing. The leading faults are modeled as the most central faults in the fault dependency network. We present ComReg, a test-case prioritization technique based on the dependency network of faults. We model a fault dependency network as a directed graph and identify leading faults to prioritize test cases for regression testing. We use a centrality aggregation technique which considers six network representative centrality metrics to identify leading faults in the fault dependency network. We also discuss the use of fault communities to select an arbitrary percentage of the test cases from a prioritized regression test suite. We conduct a case study that evaluates the effectiveness and applicability of the proposed method. We obtain a fault dependency network from the development of a vocabulary learning software. We found that the fault network is a small-world graph with distinguishable community structure. The leading faults are common in all centralities and a re-ordering of test cases is feasible for regression testing based on those leading faults. Our method outperforms traditional regression testing prioritization techniques in detecting fault dependencies. Our modeling of the network of faults provides insights into the requirement of recognizing fault dependencies while re-ordering regression test suites for both research and practice. The dependency model needs further evaluation and improvement considering relevant resources (e.g., man-hours).


<p class="paragraph_style"><a name="content_abusers_www"></a> The Social World of Content Abusers in Community Question Answering
<p class="paragraph_style_1">

Community-based question answering platforms can be rich sources of information on a variety of specialized topics, from finance to cooking. The usefulness of such platforms depends heavily on user contributions (questions and answers), but also on respecting the community rules. As a crowd-sourced service, such platforms rely on their users for monitoring and flagging content that violates community rules.

<p class="paragraph_style_1">
Common wisdom is to eliminate the users who receive many flags. Our analysis of a year of traces from a mature Q&A site shows that the number of flags does not tell the full story: on one hand, users with many flags may still contribute positively to the community. On the other hand, users who never get flagged are found to violate community rules and get their accounts suspended. This analysis, however, also shows that abusive users are betrayed by their network properties: we find strong evidence of homophilous behavior and use this finding to detect abusive users who go under the community radar. Based on our empirical observations, we build a classifier that is able to detect abusive users with an accuracy as high as 83%.

<p class="paragraph_style"><a name="prometheous_TOI"></a> Enabling Social Applications via Decentralized Social Data Management
<p class="paragraph_style_1">
An unprecedented information wealth produced by online social networks, further augmented by location/collocation data, is currently fragmented across different proprietary services. Combined, it can accurately represent the social world and enable novel socially-aware applications. We present Prometheus, a socially-aware peer-to-peer service that collects social information from multiple sources into a multigraph managed in a decentralized fashion on user-contributed nodes, and exposes it through an interface implementing non-trivial social inferences while complying with user-defined access policies. Simulations and experiments on PlanetLab with emulated application workloads show the system exhibits good end-to-end response time, low communication overhead and resilience to malicious attacks.

<p class="paragraph_style"><a name="ties_socinfo"></a> The Influence of Indirect Ties on Social Network Dynamics
<p class="paragraph_style_1">
While direct social ties have been intensely studied in the context of computer-mediated social networks, indirect ties (e.g., friends of friends) have seen less attention. Yet in real life, we often rely on friends of our friends for recommendations (of doctors, schools, or babysitters), for introduction to a new job opportunity, and for many other occasional needs. In this work we empirically study the predictive power of indirect ties in two dynamic processes in social networks: new link formation and information diffusion. We not only verify the predictive power of indirect ties in new link formation but also show that this power is effective over longer social distance. Moreover, we show that the strength of an indirect tie positively correlates to the speed of forming a new link between the two end users of the indirect tie. Finally, we show that the strength of indirect ties can serve as a predictor for diffusion paths in social networks.

<p class="paragraph_style"><a name="ties_p2p"></a> The Power of Indirect Ties in Friend-to-Friend Storage Systems
<p class="paragraph_style_1">
Friend-to-Friend (F2F) storage systems were shown to suffer from two significant limitations. First, users with a small set of friends are penalized by lack of available storage for their needs, while users with many friends get overloaded with resource requests. Second, friends are typically in close geographical proximity to each other, and thus their online times are synchronized, leading to low data availability when they are offline. This paper addresses these concerns by expanding the set of storage resources while still using a measure of social incentives. It proposes an indirect tie measurement to compute the social strength between possibly distant nodes in a social network. Using datasets from co-authorship networks and a video gaming community, we show that the social strength-based mechanism more than doubles the set of storage candidates motivated by social incentives, invites socially low connected users to contribute more resources and improves data availability by up to 6.5 times. We also show that our method complemented with simple load balancing strategies significantly improves peer engagement and workload distribution in F2F storage systems.

<p class="paragraph_style"><a name="blogretention_socialcom"></a> To Blog or Not to Blog: Characterizing and Predicting Retention in Community Blogs
<p class="paragraph_style_1">
Community blogging is a medium for  publishing daily journals, expressing opinions or ideas, and sharing knowledge. Blogging has a high impact on marketing, shaping public opinions, and informing the world about major events from a grassroots point of view. However, turnover in online blogging is very high, with most people who initially join and start contributing to the community, failing to contribute in the long run. 

<p class="paragraph_style_1">
In this paper, we ask what factors cause a blogger to continue participating in the community by contributing content (e.g., posts, comments). We crawled a sample of blogger profiles from a popular community blogging platform ``Blogster''. These bloggers contributed about 91% posts in the community. We derived a set of well-grounded variables related to blogger retention and built a predictive model from the variables. Our results show that the male and aged (senior) bloggers, who face fewer constraints and have more opportunities in the community are more retained than others. Other bloggers pay a high degree of attention to these retained bloggers through implicit (reading posts) and explicit (writing comments) interactions.

<p class="paragraph_style_1">
We have also found that a blogger has higher retention if her friends have also higher retention and a strong social tie reduces retention imbalance between two blogger friends. However, we found that a blogger's network age (e.g., how long ago she joined) has no effect on her retention. Our work has theoretical implications for the social behavior literature of bloggers, and practical implications for potential community blogging platform developers.


<p class="paragraph_style"><a name="cheating_TOI"></a> Cheating in Online Games: A Social Network Perspective
<p class="paragraph_style_1">
Online gaming is a multi-billion dollar industry that entertains a large, global population. One unfortunate phenomenon, however, poisons the competition and spoils the fun: cheating. The costs of cheating span from industry-supported expenditures to detect and limit it, to victims' monetary losses due to cyber crime.


<p class="paragraph_style_1">
This paper studies cheaters in the Steam Community, an online social network built on top of the world's dominant digital game delivery platform. We collected information about more than 12 million gamers connected in a global social network, of which more than 700 thousand have their profiles flagged as cheaters. We also observed timing information of the cheater flags, as well as the dynamics of the cheaters' social neighborhoods.

<p class="paragraph_style_1">
We discovered that cheaters are well embedded in the social and interaction networks: their network position is largely indistinguishable from that of fair players. Moreover, we noticed that the number of cheaters is not correlated with the geographical, real-world population density, or with the local popularity of the Steam Community. Also, we observed a social penalty involved with being labeled as a cheater: cheaters lose friends immediately after the cheating label is publicly applied.

<p class="paragraph_style_1">
Most importantly, we observed that cheating behavior spreads through a social mechanism: the number of cheater friends of a fair player is correlated with the likelihood of her becoming a cheater in the future. This allows us to propose ideas for limiting cheating contagion.

<p class="paragraph_style"><a name="stfunoob"></a> STFU NOOB! Predicting Crowdsourced Decisions on Toxic Behavior in Online Games
<p class="paragraph_style_1">
One problem facing players of competitive games is negative, or toxic, behavior. League of Legends, the largest eSport game, uses a crowdsourcing platform called the Tribunal to judge whether a reported toxic player should be punished or not. The Tribunal is a two stage system requiring reports from those players that directly observe toxic behavior, and human experts that review aggregated reports. While this system has successfully dealt with the vague nature of toxic behavior by majority rules based on many votes, it naturally requires tremendous cost, time, and human efforts.


<p class="paragraph_style_1">
In this paper, we propose a supervised learning approach for predicting crowdsourced decisions on toxic behavior with large-scale labeled data collections; over 10 million user reports involved in 1.46 million toxic players and corresponding crowdsourced decisions. Our result shows good performance in detecting overwhelmingly majority cases and predicting crowdsourced decisions on them. We demonstrate good portability of our classifier across regions. Finally, we estimate the practical implications of our approach, potential cost savings and victim protection.

<p class="paragraph_style"><a name="buffet"></a> Last Call for the Buffet: Economics of Cellular Networks
<p class="paragraph_style_1">
Voice and data traffic growth over the last several years has become a major challenge for cellular operators with a direct impact on revenues, infrastructure investments, and end-user performance. The economics of these operators depend on various incentives used to attract users in the form of unlimited, buffet-like voice/sms/data packages. However, our understanding of the effects of user behavior under these offerings on operator revenues/costs remains poor. Using two years of detailed usage information of ~1 million users across three services, voice, sms and data, combined with payment and cost information, we study how user behavior affects the economics of cellular operators. We discover that around 20% of the users consume more resources than wha	t they pay for and hence are non-profitable. In addition to the individual user behavior, we study how the user interactions in the call graph affect the operator's revenues and cost, drawing on tools from social network analysis. We develop a framework that incorporates both the individual and social user behavior for studying how volume caps influence the revenues and the traffic costs. Using this framework we empirically show that volume caps can increase the difference between the revenues and the traffic costs of the studied operator by a factor of 2, while affecting only 16% of the existing user base.



<p class="paragraph_style"><a name="aegis"></a> Aegis: A Semantic Implementation of Privacy as Contextual Integrity in Social Ecosystems
<p class="paragraph_style_1">
Combining and incorporating rich semantics of user social data, which is currently fragmented and managed by proprietary applications, has  the potential to more accurately represent a user's social ecosystems. However, social ecosystems raise even more serious privacy concerns than today's social networks. This paper proposes to model privacy as contextual integrity by using semantic web tools and focuses on defining default privacy policies, as they have the highest impact. Through a real implementation and performance evaluation we show that such a framework is practical.

<p class="paragraph_style"><a name="relationships_under_the_microscope"></a> Relationships under the Microscope with Interaction-Backed Social Networks
<p class="paragraph_style_1">
Binary friendship declarations typical of online social networks have been shown inadequate to properly capture dynamic and meaningful social relationships between users. Interaction networks, on the other hand, rely on statistical inference and assumptions on the nature of what "friendship" means.


<p class="paragraph_style_1">
This paper analyzes an interaction-backed social network, where an interaction network and a declared social network co-exist without constraining each other. We show quantitatively what a declared relationship carry in terms of number of interactions, but also that there are interactions between users without a declared relationship. By measuring interactions between declared and non-declared pairs of users, we can discover how levels of interaction wax and wane, and how attention is diverted from existing relationships to forming new ones. Our quantitative
analysis can also serve scientists to create interaction workloads from declared social networks or infer social networks from interaction traces.


<p class="paragraph_style"><a name="architecture_Longitudinal_social_data"></a> An Architecture for Collecting Longitudinal Social Data
<p class="paragraph_style_1">
As social computing reaches maturity, two research problems crystallize. On one hand, longitudinal studies of social media interactions become necessary for understanding, for example, how information and behavior diffuses through social networks. On the other hand, accurate representation of a person's social sphere requires aggregation of multiple sources of social data, such as online social networks, and interactions from email or instant messaging.

<p class="paragraph_style_1">This paper presents a platform for the collection, extraction and analysis of dynamic social data from multiple sources for use in observational social network research. Using an implementation of the architecture, we made daily observations of the cheating behavior of over 9 million gamers in a planetary scale online social network, finding new evidence that the spread of unethical behavior follows a contagion process and that a social penalty exists for publicly outed deviant actors.

<p class="paragraph_style"><a name="out_of_the_wild"></a> Out of the Wild: On Generating Default Policies in Social Ecosystems
<p class="paragraph_style_1">
Combining and incorporating rich semantics of user social data, which is currently fragmented and managed by proprietary applications, has the potential to more accurately represent a user's social ecosystems. However, social ecosystems raise even more serious privacy concerns than today's social networks. This paper proposes to model privacy as contextual integrity by using semantic web tools and focuses on defining default privacy policies, as they have the highest impact.

<p class="paragraph_style"><a name="bloginfluence"></a> How Influential are You: Detecting Influential Bloggers in a Blogging Community
<p class="paragraph_style_1">
Blogging is a popular activity with high impact on marketing, shaping public opinions, and informing the world about major events from a grassroots point of view. Influential bloggers are recognized by businesses as significant forces for product promotion or demotion, and by oppressive political regimes as serious threats to their power. This paper studies the problem of identifying influential bloggers in a blogging community, BlogCatalog, by using network centrality metrics. Our analysis shows that bloggers are connected in a core-periphery network structure, with the highly influential bloggers well connected with each others forming the core, and the non-influential bloggers at the periphery. The six node centrality metrics we analyzed are highly correlated, showing that an aggregate centrality score as a measure of influence will be stable to variations in centrality metrics.

<p class="paragraph_style"><a name="kpath_journal"></a> Identifying high betweenness centrality nodes in large social networks
<p class="paragraph_style_1">This paper proposes an alternative way to identify nodes with high betweenness centrality. It introduces a new metric, k-path centrality, and a randomized algorithm for estimating it, and shows empirically that nodes with high k-path centrality have high node betweenness centrality. The randomized algorithm runs in time O(k^3*n^(2-2a)*log n) and outputs, for each vertex v, an estimate of its k-path centrality up to additive error of ±n^(1/2+a) with probability 1 - 1/n^2. Experimental evaluations on real and synthetic social networks show improved accuracy in detecting high betweenness centrality nodes and significantly reduced execution time when compared with existing randomized algorithms.

<p class="paragraph_style"><a name="hourglass"></a> The Social Hourglass: an Infrastructure for Socially-aware Applications and Services
<p class="paragraph_style_1">This article proposes an infrastructure for enabling socially-aware applications and services. Following the inspiration of the hourglass architecture of the Internet, the article argues that a service that manages data from a variety of social sensors is likely to provide better accuracy in quantifying social relationships and better support for a variety of future social applications. We present an architecture that includes social sensors that capture and interpret social signals based on the interaction between two users, a personal aggregator of social information, a data management service that builds and maintains an augmented social graph, and a set of social inference functions as this service's API for social applications. As a proof of concept, we build a social sensor for multiplayer online gaming interactions and draw a set of observations and lessons for future work.

<p class="paragraph_style"><a name="cheater"></a> Branded with a Scarlet "C": Cheaters in a Gaming Social Network
<p class="paragraph_style_1"> Online gaming is a multi-billion dollar industry that entertains a large, global population. One unfortunate phenomenon, however, poisons the competition and the fun: cheating. The costs of cheating span from industry-supported expenditures to detect and limit cheating, to victims' monetary losses due to cyber crime.
<p class="paragraph_style_1"> This paper studies cheaters in the Steam Community, an online social network built on top of the world's dominant digital game delivery platform. We collected information about more than 12 million gamers connected in a global social network, of which more than 700 thousand have their profiles flagged as cheaters. We also collected in-game interaction data of over 10 thousand players from a popular multiplayer gaming server. We show that cheaters are well embedded in the social and interaction networks: their network position is largely indistinguishable from that of fair players. We observe that the cheating behavior appears to spread through a social mechanism: the presence and the number of cheater friends of a fair player is correlated with the likelihood of her becoming a cheater in the future. Also,we observe that there is a social penalty involved with being labeled as a cheater: cheaters are likely to switch to more restrictive privacy settings once they are tagged and they lose more friends than fair players. Finally, we observe that the number of cheaters is not correlated with the geographical, real-world population density, or with the local popularity of the Steam Community.

<p class="paragraph_style"><a name="peer-centrality"></a> Inferring Peer Centrality in Socially-Informed Peer-to-Peer Systems
<p class="paragraph_style_1">Social applications implemented on a peer-to-peer (P2P) architecture mine the social graph of their users for improved performance in search, recommendations, resource sharing and others. In such applications, the social graph that connects their users is distributed on the peer-to-peer system: the traversal of the social graph translates to a socially-informed routing in the peer-to-peer layer.
<p class="paragraph_style_1">In this work we introduce the model of a projection graph that is the result of mapping a social graph onto a peer-to-peer network. We analytically formulate the relation between metrics in the social graph and in the projection graph. We focus on three such graph metrics: degree centrality, node betweenness centrality, and edge betweenness centrality. We evaluate experimentally the feasibility of estimating these metrics in the projection graph from the metrics of the social graph. Our experiments on real networks show that when mapping communities of 50-150 users on a peer, there is an optimal organization of the projection graph with respect to degree and node betweenness centrality. In this range, the association between the properties of the social graph and the projection graph is the highest, and thus the properties of the (dynamic) projection graph can be inferred from the properties of the (slower changing) social graph. We discuss the applicability of our findings to aspects of peer-to-peer systems such as data dissemination, social search, peer vulnerability, and data placement and caching.
<p class="paragraph_style"><a name="kpath"></a> K-Path Centrality: A New Centrality Measure in Social Networks
<p class="paragraph_style_1">This paper proposes an alternative way to identify nodes with high betweenness centrality. It introduces a new metric, K-path centrality, and a randomized algorithm for estimating it, and shows empirically that nodes with high K-path centrality have high node betweenness centrality. Experimental evaluations on diverse real and synthetic social networks show improved accuracy in detecting high betweenness centrality nodes and significantly reduced execution time when compared to known randomized algorithms.
<p class="paragraph_style"><a name="vulnerability"></a> Vulnerability in Socially-Informed Peer-to-Peer Systems
<p class="paragraph_style_1">The recent increase in the volume of recorded social interactions has the potential to enable a large class of innovative social applications and services. The decentralized management of such social information as a social graph distributed on a user-contributed peer-to-peer network is appealing due to privacy concerns. This paper studies the vulnerability of such a peer-to-peer system to attacks staged by malicious users who try to manipulate the graph or by malicious peers who try to manipulate the mining of the social graph. We discuss the effects and limitations of such attacks and we show experimentally how the distribution of the social data onto peers affects the system's resilience.
<p class="paragraph_style"><a name="lopsil-finnis"></a> A Location-based Policy-specification Language for Mobile Devices
<p class="paragraph_style_1">The dramatic rise in mobile applications has greatly increased threats to the security and privacy of users. Security mechanisms on mobile devices are currently limited, so users need more expressive ways to ensure that downloaded mobile applications do not act maliciously. Policy-specification languages were created for this purpose; they allow the enforcement of user-defined policies on third-party applications. We have implemented LoPSiL, a location-based policy-specification language for mobile devices. This article describes LoPSiL's design and implementation, several example policies, and experiments that demonstrate LoPSiL's viability for enforcing policies on mobile devices.
<p class="paragraph_style"><a name="prometheus"></a> Prometheus: User-Controlled P2P Social Data Management for Socially-Aware Applications
<p class="paragraph_style_1">Recent Internet applications, such as online social networks and user-generated content sharing, produce an unprecedented amount of social information, which is further augmented by location or collocation data collected from mobile phones. Unfortunately, this wealth of social information is fragmented across many different proprietary applications. Combined, it could provide a more accurate representation of the social world, and it could enable a whole new set of socially-aware applications. We introduce Prometheus, a peer-to-peer service that collects and manages social information from multiple sources and implements a set of social inference functions while enforcing user-defined access control policies. Prometheus is socially-aware: it allows users to select peers that manage their social information based on social trust and exploits naturally-formed social groups for improved performance. We tested our Prometheus prototype on PlanetLab and built a mobile social application to test the performance of its social inference functions under real-time constraints. We showed that the social-based mapping of users onto peers improves the service response time and high service availability is achieved with low overhead.
<p class="paragraph_style"><a name="gdc"></a>GDC: Group Discovery using Co-location Traces
<p class="paragraph_style_1">Smart phones can collect and share Bluetooth co-location traces to identify ad hoc or semi-permanent social groups. This information, known to group members but otherwise unavailable, can be leveraged in applications and protocols, such as recommender systems or delay-tolerant forwarding in ad hoc networks, to enhance the user experience. Group discovery using Bluetooth co-location is practical because: (i) Bluetooth is embedded in nearly every phone and has low battery consumption, (ii) the short wireless transmission range can lead to good group identification accuracy, and (iii) privacy-conscious users are more likely to share co-location data than absolute location data.
This paper proposes the Group Discovery using Co-location traces (GDC) algorithm, which leverages user meeting frequency and duration to accurately detect groups. GDC is validated on one month of data collected from 141 smart phones carried by students on our campus. Users rated GDC's groups 30% better than groups discovered using the K-Clique algorithm. Additionally, GDC lends itself more easily to a distributed implementation, which achieves similar results with the centralized version while improving user's privacy.
<p class="paragraph_style"><a name="affinity"></a> Affinity P2P: A self-organizing content-based locality-aware collaborative peer-to-peer network 
<p class="paragraph_style_1">The last years have brought a dramatic increase in the popularity of collaborative Web 2.0 sites. According to recent evaluations, this phenomenon accounts for a large share of Internet traffic and significantly augments the load on the end-servers of Web 2.0 sites. In this paper, we show how collaborative classifications extracted from Web 2.0-like sites can be leveraged in the design of a self-organizing peer-to-peer network in order to distribute data in a scalable manner while preserving a high-content locality. We propose Affinity P2P (AP2P), a novel cluster-based locality-aware self-organizing peer-to-peer network. AP2P self-organizes in order to improve content locality using a novel affinity-based metric for estimating the distance between clusters of nodes sharing similar content. Searches in AP2P are directed to the cluster of interests, where a logarithmic-time parallel flooding algorithm provides high recall, low latency, and low communication overhead. The order of clusters is periodically changed using a greedy cluster placement algorithm, which reorganizes clusters based on affinity in order to increase the locality of related content. The experimental and analytical results demonstrate that the locality-aware cluster-based organization of content offers substantial benefits, achieving an average latency improvement of 45%, and up to 12% increase in search recall.
<p class="paragraph_style"><a name="geos"></a> On Managing Social Data for Enabling Socially-Aware Applications and Services
<p class="paragraph_style_1">Applications and services that take advantage of social data usually infer social relationships using information produced only within their own context. We propose to combine social information from multiple sources into a directed and weighted social multigraph in order to enable novel socially-aware applications and services. We present GeoS, our early prototype of a geo-social data management service which implements a representative set of social inferences. We demonstrate GeoS' potential for social applications on a collection of social data that combines collocation information and Facebook friendship declarations from 100 students. 
<p class="paragraph_style"><a name="smallworld"></a> The Small World of File Sharing
<p class="paragraph_style_1">Web caches, content distribution networks, peer-to-peer file sharing networks, distributed file systems, and data grids all have in common that they involve a community of users who use shared data. In each case, overall system performance can be improved significantly by first identifying and then exploiting the structure of community's data access patterns.
<p class="paragraph_style_1">We propose a novel perspective for analyzing data access workloads that considers the implicit relationships that form among users based on the data they access. We propose a new structure&#151;the interest-sharing graph&#151;that captures common user interests in data and justify its utility with studies on four data-sharing systems: a high-energy physics collaboration, the Web, the Kazaa peer-to-peer network, and a BitTorrent file-sharing community. We find small-world patterns in the interest-sharing graphs of all four communities. We investigate analytically and experimentally some of the potential causes that lead to this pattern and conclude that user preferences play a major role.
<p class="paragraph_style_1">The significance of small-world patterns is two-fold: it provides a rigorous support to intuition and it suggests the potential to exploit these naturally emerging patterns. As a proof of concept, we design and evaluate an information dissemination system that exploits the small-world interest-sharing graphs by building an interest-aware network overlay. We show that this approach leads to improved information dissemination performance. 
<p class="paragraph_style"><a name="lopsil"></a>LoPSiL: A Location-based Policy-specification Language
<p class="paragraph_style_1">This paper describes the design of LoPSiL, a language for specifying location-dependent security and privacy policies. Policy- specification languages like LoPSiL are domain-specific programming languages intended to simplify the tasks of specifying and enforcing sound security policies on untrusted (i.e., potentially insecure) software. As far as we are aware, LoPSiL is the first imperative policy-specification language to provide abstractions specifically tailored to location-dependent policies for mobile-device applications. We have implemented a proof-of-concept compiler that inputs a LoPSiL policy P and a mobile-device application program A and outputs a new application program A equivalent to A, except that A contains inlined enforcement code that ensures that A satisfies P at runtime. We report our experiences using this compiler to design and implement several policies for mobile-device applications. 
<p class="paragraph_style"><a name="tagging"></a> Individual and Social Behavior in Tagging Systems
<p class="paragraph_style_1">In tagging systems users can annotate items of interest with free-form terms. A good understanding of the usage characteristics of such systems is necessary to improve the design of current and next generation tagging systems. To this end, this work explores three aspects of user behavior in CiteULike and Connotea, two systems that include tagging features to support online personalized management of scientific publications. First, this study characterizes the degree to which users re-tag previously published items and reuse tags: 10 to 20% of the daily activity can be characterized as re-tagging and about 75% of the activity as tag reuse. Second, we use the pairwise similarity between users' activity to characterize the interest sharing in these systems. We present the interest sharing distribution across the systems, show that this metric encodes information about existing usage patterns, and attempt to correlate interest sharing levels to indicators of collaboration such as co-membership in discussion groups and semantic similarity of tag vocabularies. Finally, we show that interest sharing leads to an implicit structure that exhibits a natural segmentation. Throughout the paper we discuss the potential impact of our findings on the design of mechanisms that support tagging systems. 
<p class="paragraph_style"><a name="resource"></a> Workload characterization in a high-energy data grid and impact on resource management
<p class="paragraph_style_1">The analysis of data usage in a large set of real traces from a high-energy physics collaboration revealed the existence of an emergent grouping of files that we coined "filecules". This paper presents the benefits of using this file grouping for prestaging data and compares it with previously proposed file grouping techniques along a range of performance metrics. Our experiments with real workloads demonstrate that filecule grouping is a reliable and useful abstraction for data management in science Grids; that preserving time locality for data prestaging is highly recommended; that job reordering with respect to data availability has significant impact on throughput; and finally, that a relatively short history of traces is a good predictor for filecule grouping. Our experimental results provide lessons for workload modeling and suggest design guidelines for data management in data-intensive resource-sharing environments.
<p class="paragraph_style"><a name="music"></a> Beyond Music Sharing: An Evaluation of Peer-to-Peer Data Dissemination Techniques in Large Scientific Collaborations
<p class="paragraph_style_1">The avalanche of data from scientific instruments and the ensuing interest from geographically distributed users to analyze and interpret it accentuates the need for efficient data dissemination. A suitable data distribution scheme will find the delicate balance between conflicting requirements of minimizing transfer times, minimizing the impact on the network, and uniformly distributing load among participants. We identify several data distribution techniques, some successfully employed by today's peer-to-peer networks: staging, data partitioning, orthogonal bandwidth exploitation, and combinations of the above. 
<p class="paragraph_style"><a name="socapps"></a> P2P Systems Meet Mobile Computing: A Community-Oriented Software Infrastructure for Mobile Social Applications
<p class="paragraph_style_1">The widespread adoption of powerful mobile devices creates an unprecedented potential for innovative mobile applications that can enhance users' social interactions. The current centralized mobile system and service architectures do not allow large-scale dynamic interactions between mobile devices, as required by these applications. This paper proposes Mobius, a decentralized solution that supports mobile social applications via a two-tier software infrastructure. In Mobius, a socially-aware peer-to-peer tier provides community-oriented data and persistent services for the mobile tier that runs the applications. 
<p class="paragraph_style"><a name="file"></a> File Grouping for Scientific Data Management: Lessons from Experimenting with Real Traces
<p class="paragraph_style_1">The analysis of data usage in a large set of real traces from a high-energy physics collaboration revealed the existence of an emergent grouping of files that we coined "filecules". This paper presents the benefits of using this file grouping for prestaging data and compares it with previously proposed file grouping techniques along a range of performance metrics. Our experiments with real workloads demonstrate that filecule grouping is a reliable and useful abstraction for data management in science Grids; that preserving time locality for data prestaging is highly recommended; that job reordering with respect to data availability has significant impact on throughput; and finally, that a relatively short history of traces is a good predictor for filecule grouping. 
<p class="paragraph_style_1">Our experimental results provide lessons for workload modeling and suggest design guidelines for data management in data-intensive resource-sharing environments.
<p class="paragraph_style"><a name="s3"></a> Amazon S3 for Science Grids: a Viable Solution?
<p class="paragraph_style_1">Amazon.com has introduced the Simple Storage Service (S3), a commodity-priced storage utility. S3 aims to provide storage as a low-cost, highly available service, with a simple 'pay-as-you-go' charging model. This article makes three contributions. First, we evaluate S3's ability to provide storage support to large-scale science projects from a cost, availability, and performance perspective. Second, we identify a set of additional functionalities that storage services targeting data-intensive science applications should support. Third, we propose unbundling the success metrics for storage utility performance as a solution, to reduce storage costs. 
<p class="paragraph_style"><a name="grid"></a> Data Transfers in the Grid: Workload Analysis of Globus GridFTP
<p class="paragraph_style_1">One of the basic services in grids is the transfer of data between remote machines. Files may be transferred at the explicit request of the user or as part of delegated resource management services, such as data replication or job scheduling. GridFTP is an important tool for such data transfers since it builds on the common FTP protocol, has a large user base with multiple implementations, and it uses the GSI security model that allows delegated operations.
<p class="paragraph_style_1">This paper presents a workload analysis of the implementation of the GridFTP protocol provided by the Globus Toolkit. We studied more than 1.5 years of traces reported from all over the world by Globus GridFTP installed components. Our study focuses on three dimensions: first, it quantifies the volume of data transferred and characterizes user behavior. Second, it attempts to show how tuning capabilities are used in practice. Finally, it quantifies the user base as recorded in the database and highlights the usage trends of this software component. 
<p class="paragraph_style"><a name="content"></a> Content Reuse and Interest Sharing in Tagging Communities
<p class="paragraph_style_1">Tagging communities represent a subclass of a broader class of user-generated content-sharing online communities. In such communities users introduce and tag content for later use. Although recent studies advocate and attempt to harness social knowledge in this context by exploiting collaboration among users, little research has been done to quantify the current level of user collaboration in these communities. This paper introduces two metrics to quantify the level of collaboration: content reuse and shared interest. Using these two metrics, this paper shows that the current level of collaboration in CiteULike and Connotea is consistently low, which significantly limits the potential of harnessing the social knowledge in communities. This study also discusses implications of these findings in the context of recommendation and reputation systems.
<p class="paragraph_style"><a name="globus"></a> The Globus Replica Location Service: Design and Experience
<p class="paragraph_style_1">Distributed computing systems employ replication to improve overall system robustness, scalability and performance. A Replica Location Service (RLS) offers a mechanism to maintain and provide information about physical locations of replicas. This paper defines a design framework for replica location services that supports a variety of deployment options. We describe the RLS implementation that is distributed with the Globus Toolkit and is in production use in several Grid deployments. Features of our modular implementation include the use of soft-state protocols to populate a distributed index and Bloom filter compression to reduce overheads for distribution of index information. Our performance evaluation demonstrates that the RLS implementation scales well for individual servers with millions of entries and up to one hundred clients. We describe the characteristics of existing RLS deployments and discuss how RLS has been integrated with higher-level data management services. 
<p class="paragraph_style"><a name="simplicity"></a> In Search of Simplicity: A Self-Organizing Group Communication Overlay
<p class="paragraph_style_1">Group communication primitives have broad utility as building blocks for distributed applications. The challenge is to create and maintain the distributed structures that support these primitives while accounting for volatile end-nodes and variable network characteristics. Most solutions proposed to date rely on complex algorithms or global information, thus limiting the scale of deployments and acceptance outside the academic realm.
<p class="paragraph_style_1">This article introduces a low-complexity, self-organizing solution for maintaining multicast trees, that we refer to as UMM (Unstructured Multi-source Multicast). UMM uses traditional distributed systems techniques: layering, soft-state, and passive data collection to adapt to the dynamics of the physical network and maintain data dissemination trees. The result is a simple, adaptive system with lower overheads than more complex alternatives. We have implemented UMM and evaluated it on up to 1024-node emulated ModelNet networks and on the PlanetLab testbed. Extensive experimental evaluations and quantitative comparisons with alternative solutions demonstrate UMM's low overhead, efficient network usage, and ability to quickly adapt to network changes and to recover from failures. 
<p class="paragraph_style"><a name="tracking"></a> Tracking Usage in Collaborative Tagging Communities
<p class="paragraph_style_1">Collaborative tagging has recently attracted the attention of both industry and academia due to the popularity of content-sharing systems such as CiteULike, del.icio.us, and Flickr. These systems give users the opportunity to add data items and to attach their own metadata (i.e., tags) to stored data. The result is an effective content management tool for individual users. Recent studies, however, suggest that, as tagging communities grow, the added content and the metadata become harder to manage due to increased content diversity. Thus, mechanisms that cope with increase of diversity are fundamental to improve the scalability and usability of collaborative tagging systems.
<p class="paragraph_style_1">This paper analyzes whether usage patterns can be harnessed to improve navigability in a growing knowledge space. To this end, it presents a characterization of two collaborative tagging communities that target the management of scientific literature: CiteULike and Bibsonomy. We explore three main directions: First, we analyze the tagging activity distribution across the user population. Second, we define new metrics for similarity in user interest and use these metrics to uncover the structure of the tagging communities we study. The properties of the structure we uncover suggest a clear segmentation of interests into a large number of individuals with unique preferences and a core set of users with interspersed interests. Finally, we offer preliminary results that suggest that the interest-based structure of the tagging community can be used to facilitate content retrieval and navigation as communities scale. 
<p class="paragraph_style"><a name="science"></a> Are P2P Data-Dissemination Techniques Viable in Today's Data-Intensive Scientific Collaborations?
<p class="paragraph_style_1">The interest among a geographically distributed user base to mine massive collections of scientific data propels the need for efficient data dissemination solutions. An optimal data distribution scheme will find the delicate and often application-specific balance among conflicting success metrics such as minimizing transfer times, minimizing the impact on the network, and uniformly distributing load among participants. We use simulations to explore the performance of main classes of data-distribution techniques, some of the successfully deployed by large peer-to-peer communities, in the context of today's data-centric scientific collaborations. Based on these simulations we derive several recommendations for data distribution in real-world science collaborations. 
<p class="paragraph_style"><a name="doctrine"></a> Toward a Doctrine of Containment: Grid Hosting with Adaptive Resource
<p class="paragraph_style_1">Grid computing environments need secure resource control and predictable service quality in order to be sustainable. We propose a grid hosting model in which independent, self-contained grid deployments run within isolated containers on shared resource provider sites. Sites and hosted grids interact via an underlying resource control plane to manage a dynamic binding of computational resources to containers. We present a prototype grid hosting system, in which a set of independent Globus grids share a network of cluster sites. Each grid instance runs a coordinator that leases and configures cluster resources for its grid on demand. Experiments demonstrate adaptive provisioning of cluster resources and contrast job-level and container-level resource management in the context of two grid application managers.
<p class="paragraph_style"><a name="filecules"></a> Filecules in High-Energy Physics: Characteristics and Impact on Resource Management
<p class="paragraph_style_1">Grid computing has reached the stage where deployments are mature and many collaborations run in production mode. Mature Grid deployments offer the opportunity for revisiting and perhaps updating traditional beliefs related to workload models, which in turn leads to the reevaluation of traditional resource management techniques. 
<p class="paragraph_style_1">This paper analyzes usage patterns in a typical Grid community, a large-scale data-intensive scientific collaboration in high-energy physics. We focus mainly on data usage, since data is the major resource for this class of applications. Our observations led us to propose a new abstraction for resource management in scientific data analysis applications: we define a filecule as a group of files that is always used together. We show that filecules exist and present their characteristics. The existence of filecules suggests a new granularity for data management, which, if incorporated in design, can significantly outperform the traditional solutions for data caching, replication and placement based on single-file granularity. We reason about the impact of filecules on resource management and show compelling evidence for using this abstraction when designing data management services. 
<p class="paragraph_style"><a name="S4"></a>S4: A Simple Storage Service for Sciences
<p class="paragraph_style_1">Amazon's Simple Storage Service (S3) is a storage utility that bundles at a single pricing point three storage system characteristics: high data durability, high availability, and high-speed data access. Many applications, and scientific applications in particular, do not need all these three characteristics bundled together. We argue that unbundling offers an opportunity to provide acceptably-priced storage and that future storage utilities designed to support science communities can offer multiple classes of service without introducing hidden, complexity-related costs. 

<p class="paragraph_style"><a name="blogretention_bigdata"></a>Did You Blog Yesterday? Retention in Community Blogs
<p class="paragraph_style_1">
We ask what factors cause a blogger to continue participating in the community by contributing content  (e.g., posts, comments). We crawled a sample of blogger profiles (contributed 91% posts) from a popular community blogging platform ``Blogster''. Our results show that the male and aged (senior) bloggers, who face fewer constraints and have more opportunities in the community are more retained than others. Other bloggers pay a high degree of attention to these retained bloggers through implicit (reading posts) and explicit (writing comments) interactions.  We have also found that a blogger has higher retention if her friends have also higher retention and a strong social tie reduces retention imbalance between two blogger friends. However, we found that a blogger's network age (e.g., how long ago she joined) has no effect on her retention.




<p class="paragraph_style"><a name="jeremy"></a>An Analysis of (Bad) Behavior in Online Video Games
<p class="paragraph_style_1">This dissertation studies bad behavior at large-scale using data traces from online video games. Video games provide a natural laboratory for exploring bad behavior due to their popularity, explicitly defined (programmed) rules, and a competitive nature that provides motivation for bad behavior. More specifically, we look at two forms of bad behavior: cheating and toxic behavior.
<p class="paragraph_style_1">Cheating is most simply defined as breaking the rules of the game to give one player an edge over another. In video games, cheating is most often accomplished using programs, or 'hacks,' that circumvent the rules implemented by game code. Cheating is a threat to the gaming industry in that it diminishes the enjoyment of fair players, siphons off money that is paid to cheat creators, and requires investment in anti-cheat technologies.
<p class="paragraph_style_1">Toxic behavior is a more nebulously defined term, but can be thought of as actions that violate social norms, especially those that harm other members of the society. Toxic behavior ranges from insults or harassment of players (which has clear parallels to the real world) to domain specific instances such as repeatedly 'suiciding' to help an enemy team. While toxic behavior has clear parallels to bad behavior in other online domains, e.g., cyberbullying, if gone unchecked it has the potential to 'kill' a game by driving away its players.
<p class="paragraph_style_1">We first present a distributed architecture and reference implementation for the collection and analysis of large-scale social data. Using this implementation we then study the social structure of over 10 million gamers collected from a planetary scale Online Social Network, about 720 thousand of whom have been labeled cheaters, finding a significant correlation between social structure and the probability of partaking in cheating behavior. We additionally collect over half a billion daily observations of the cheating status of these gamers. Using about 10 months of detailed server logs from a community owned and operated game server we next analyze how relationships in the aforementioned online social network are backed by in-game interactions. Next, we use the insights gained and find evidence for a contagion process underlying the spread of cheating behavior and perform a data driven simulation using mathematical models for contagion. Finally, we build a model using millions of crowdsourced decisions for predicting toxic behavior in online games.

<p class="paragraph_style_1">To the best of our knowledge, this dissertation presents the largest study of bad behavior to date. Our findings confirm theories about cheating and unethical behavior that have previously remained untested outside of controlled laboratory experiments or only with small, survey based studies. We find that the intensity of interactions between players is a predictor of a future relationship forming. We provide statistically significant evidence for cheating as a contagion. Finally, we extract insights from our model for detecting toxic behavior on how human reviewers perceive the presence and severity of bad behavior.

<p class="paragraph_style"><a name="nicolas"></a>On the Design of Socially-Aware Distributed Systems
<p class="paragraph_style_1">Social media services and applications enable billions of users to share an unprecedented amount of social information, which is further augmented by location and collocation information from mobile phones, and can be aggregated to provide an accurate digital representation of the social world. This dissertation argues that extracted social knowledge from this wealth of information can be embedded in the design of novel distributed, socially-aware applications and services, consequently improving system response time, availability and resilience to attacks, and reducing system overhead. To support this thesis, two research avenues are explored.First, this dissertation presents Prometheus, a socially-aware peer-to-peer service that collects social information from multiple sources, maintains it in a decentralized fashion on user-contributed nodes, and exposes it to applications through an interface that implements non-trivial social inferences. The system's socially-aware design leads to multiple system improvements: 1) it increases service availability by allowing users to manage their social information via socially-trusted peers, 2) it improves social inference performance and reduces message overhead by exploiting naturally-formed social groups, and 3) it reduces the opportunity of attackers to influence application requests. These performance improvements are assessed via simulations and a prototype deployment on a local cluster and on a worldwide testbed (PlanetLab) under emulated application workloads. Second, this dissertation defines the projection graph, the result of decentralizing a social graph onto a peer-to-peer system such as Prometheus, and studies the system's network properties and how they can be used to design more efficient socially-aware distributed applications and services. In particular: 1) it analytically formulates the relation between centrality metrics such as degree centrality, node betweenness centrality, and edge betweenness centrality in the social graph and in the emerging projection graph, 2) it experimentally demonstrates on real networks that for small groups of users mapped on peers, there is high association of social and projection graph properties, 3) it shows how these properties of the (dynamic) projection graph can be accurately inferred from the properties of the (slower changing) social graph, and 4) it demonstrates with two search application scenarios the usability of the projection graph in designing social search applications and unstructured P2P overlays.
<p class="paragraph_style_1">These research results lead to the formulation of lessons applicable to the design of socially- aware applications and distributed systems for improved application performance such as social search, data dissemination, data placement and caching, as well as for reduced system communication overhead and increased system resilience to attacks.

<p class="paragraph_style"><a name="Bailey"></a>Live Video Streaming from Android-Enabled Devices to Web Browsers
<p class="paragraph_style_1">The wide-spread adoption of camera-embedded mobile devices along with the ubiquitous connection via WiFi or cellular networks enables people to visually report live events. Current solutions limit the configurability of such services by allowing video streaming only to fixed servers. In addition, the business models of the companies that provide such (free) services insert visual ads in the streamed videos, leading to unnecessary resource consumption.
<p class="paragraph_style_1">This thesis proposes an architecture of a real-time video streaming service from an Android mobile device to a server of the user's choice. The real-time video can then be viewed from a web browser. The project builds on open-source code and open protocols to implement a set of software components that successfully stream live video. Experimental evaluations show practical resource consumption and a good quality of the streamed video. Furthermore, the architecture is scalable and can support large number of simultaneous streams with additional increase in hardware resources.

<p class="paragraph_style"><a name="anderson"></a>GeoS: A Service for the Management of Geo-Social Information in a Distributed System
<p class="paragraph_style_1">Applications and services that take advantage of social data usually infer social relationships using information produced only within their own context, using a greatly simplified representation of users' social data. We propose to combine social information from multiple sources into a directed and weighted social multigraph in order to enable novel socially-aware applications and services. We present GeoS, a geo-social data management service which implements a representative set of social inferences and can run on a decentralized system. We demonstrate GeoS' potential for social applications on a collection of social data that combines collocation information and Facebook friendship declarations from 100 students. We demonstrate its performance by testing it both on PlanetLab and a LAN with a realistic workload for a 1000 node graph. 
<p class="paragraph_style"><a name="stillo"></a>Tango Panopticon: Developing a Platform for Supporting Live Synchronous Art Events Based in Relational Aesthetics
<p class="paragraph_style_1">The Tango Panopticon project merges art with technology to create a live and synchronous art experience which is just as much about the participants as it is about the observers. The goal of this project is to create a dialogue between observers of the event in the hopes of creating new social connections where there were none before. This goal is achieved by allowing observers to view the event from anywhere around the world on a computer via the internet and participate in a dialogue with other users on the website. 
<p class="paragraph_style_1">The other objective of this project is to create a multimedia internet platform for other art projects to use. Other artists that are interested in hosting their own live synchronous event will be able to use the platform we have created and customize it to the specific needs of their project. 
<p class="paragraph_style"><a name="doraimani"></a> Filecules: A New Granularity for Resource Management in Grids
<p class="paragraph_style_1">Grids provide an infrastructure for seamless, secure access to a globally distributed set of shared computing resources. Grid computing has reached the stage where deployments are run in production mode. In the most active Grid community, the scientific community, jobs are data and compute intensive. Scientific Grid deployments offer the opportunity for revisiting and perhaps updating traditional beliefs related to workload models and hence reevaluate traditional resource management techniques.
<p class="paragraph_style_1">In this thesis, we study usage patterns from a large-scale scientific Grid collaboration in high-energy physics. We focus mainly on data usage, since data is the major resource for this class of applications. We perform a detailed workload characterization which led us to propose a new data abstraction, filecule, that groups correlated files. We characterize filecules and show that they are an appropriate data granularity for resource management. 
<p class="paragraph_style_1">In scientific applications, job scheduling and data staging are tightly coupled. The only algorithm previously proposed for this class of applications, Greedy Request Value (GRV), uses a function that assigns a relative value to a job. We wrote a cache simulator that uses the same technique of combining cache replacement with job reordering to evaluate and compare quantitatively a set of alternative solutions. These solutions are combinations of Least Recently Used (LRU) and GRV from the cache replacement space with First-Come First-Served (FCFS) and the GRV-specific job reordering from the scheduling space. Using real workload from the DZero Experiment at Fermi National Accelerator Laboratory, we measure and compare performance based on byte hit rate, cache change, job waiting time, job waiting queue length, and scheduling overhead.
<p class="paragraph_style_1">Based on our experimental investigations, we propose a new technique that combines LRU for cache replacement and job scheduling based on the relative request value. This technique incurs less data transfer costs than the GRV algorithm and shorter job processing delays than FCFS. We also propose using filecules for data management to further improve the results obtained from the above LRU and GRV combination.
<p class="paragraph_style_1">We show that filecules can be identified in practical situations and demonstrate how the accuracy of filecule identification influences caching performance.
</div>     <!--end content block-->

<div class="menu"> <div class="paragraph_style">DSG at USF</div>
<ul> <li><a href="../index.html" class="menu_link">Home</a></li>
<li><a href="../projects.html" class="menu_link">Projects</a></li>
<li><a href="../publications.html" class="menu_link">Publications</a></li> 
<li><a href="../software.html" class="menu_link">Software</a></li> 
<li><a href="../members.html" class="menu_link">Members</a></li> </ul>
</div>     <!--end menu block-->

<div id="clear"></div>
</div>     <!--end main content block-->

<div id="main_content_bottom"></div>
<div id="footer"><strong>Copyright &copy; 2014</strong> | <a href="../index.html"><b>Home</b></a> | <a href="http://www.usf.edu"><b>USF</b></a> | <a href="http://www.cse.usf.edu"><b>CSE</b></a>  </div> 
</div>     <!--end container block-->
</body>
</html>

